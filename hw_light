

from hw.hw_model import HWizard
import pytorch_lightning as pl
from torch.utils.tensorboard import SummaryWriter
from pytorch_lightning.loggers import TensorBoardLogger
from torch_geometric.loader import DataLoader
from torch_geometric.data import Batch
from bn_structures_to_graph import MaterialDS, MaterialMesh, MyTensor
import matplotlib.pyplot as plt
import numpy as np 
import torch
import os

def create_directory_if_not_exists(directory_path):
    """
    Creates a directory if it does not already exist.

    Args:
    directory_path (str): The path of the directory to create.

    Returns:
    None
    """
    if not os.path.exists(directory_path):
        os.makedirs(directory_path)
        print(f"Directory created: {directory_path}")
    else:
        print(f"Directory already exists: {directory_path}")



def det_importance(targets):
    # Get unique values and their counts
    targets=targets.type(torch. int64) 
    values, counts = torch.unique(targets, return_counts=True)
    # Print the frequency of each value
    reciprocal_dict = {}
    for value, count in zip(values, counts):
        if int(value.item()) not in reciprocal_dict.keys():
            reciprocal_dict[int(value.item())] = count.item()
        else:
            reciprocal_dict[int(value.item())]  =reciprocal_dict[int(value.item())]+count.item()
        #print(f"{value.item()}: {count.item()} times")
    # print("Done")
    targets_scale = torch.tensor([1/reciprocal_dict[int(k)] for k in targets], requires_grad=False)
    return targets_scale

def plot_matrx(matrix, name='heatmap.png', path=""):
    plt.show()
    matrix = matrix.detach().numpy()
    plt.imshow(matrix, cmap='hot', interpolation='nearest')
    plt.colorbar()  # Add color bar
    plt.title(name)
    plt.savefig(path+name)
    plt.show()
    plt.clf()

def hop_on_difference(pred, targets):
    ko = 100
    kh = 5
    #

    pred_0 = pred[0][:, 0]  # .reshape([pred[0].shape[0]*2])
    targets_0 = targets[0][:, 0]  # .reshape([pred[0].shape[0] * 2])
    pred_1 = pred[1][:, 0]  # .reshape([pred[1].shape[0] * 2])
    targets_1 = targets[1][:, 0]  # .reshape([pred[1].shape[0] * 2])
    #print("pred", pred)

    # Get importance
    targets_scale_0 = det_importance(targets_0).to(pred[0].device)
    targets_scale_1 = det_importance(targets_1).to(pred[1].device)
    #print(pred_0)
    d_onsite  =torch.abs(pred_0 - targets_0)
    d_onsite =d_onsite  * targets_scale_0
    d_onsite = torch.sum(d_onsite)


    d_hop=torch.abs(pred_1 - targets_1)
    d_hop =d_hop *targets_scale_1
    d_hop = torch.sum(d_hop)
    #print(f"onsite{d_onsite}-hop:{d_hop}")
    loss =    kh * d_hop+d_hop**2 + ko * d_onsite  #

 
    return loss




def main():


    exp_name="test_hw_model_100"
    log_dir="lightning_logs/"
    logger = TensorBoardLogger(save_dir=log_dir, name=exp_name)

    lightning_model = HWizard(edge_shape=51,
                    node_shape=2,
                    u_shape=10,
                    embed_size=[20, 10, 5],
                    ham_output_size=[2,2,1],
                    orbital_blocks=3,
                    pair_interaction_blocks=2,
                    onsite_depth=2,
                    ofsite_depth=2)

    lightning_model.loss_function=hop_on_difference

    num_epochs = 2000

    training_data = torch.load('BN_database/Graphs/aBN_noxyz.pt')
    train_dataloader = DataLoader(training_data, batch_size=2, shuffle=True)
    val_dataloader = DataLoader(training_data, batch_size=4, shuffle=True)


    val_check_interval = int(len(train_dataloader))

    trainer = pl.Trainer(max_epochs = num_epochs, 
                         val_check_interval=val_check_interval, 
                         logger=logger)

    trainer.fit(lightning_model, train_dataloader, val_dataloader)


# Now letÂ´s see the results:
# create the experimant archive
    create_directory_if_not_exists(exp_name)
    create_directory_if_not_exists(f"{exp_name}/rezults")
    create_directory_if_not_exists(f"{exp_name}/rezults/img")
    create_directory_if_not_exists(f"{exp_name}/rezults/txt")
    device=lightning_model.device
    train_dataloader = DataLoader(training_data, batch_size=1, shuffle=True)
    for ko, inputs in enumerate(train_dataloader):
        inputs.to(device)
        x = inputs.x.to(torch.float32)
        edge_index = inputs.edge_index.to(torch.int64).to(device)
        edge_attr = inputs.edge_attr.to(torch.float32).to(device)
        state = inputs.u.to(torch.float32).to(device)
        batch = inputs.batch.to(device)
        bond_batch = inputs.bond_batch.to(device)
        hii, hij, ij = lightning_model(x, edge_index, edge_attr, state, batch.to(device),
                             bond_batch.to(device))
        #print("hij:", hij)
        hii = hii.to("cpu")
        hij = hij.to("cpu")
        ij = ij.to("cpu")

        pred_mat_r = torch.zeros([len(hii), len(hii)])
        pred_mat_i = torch.zeros([len(hii), len(hii)])
        for i, hi in enumerate(hii):
            pred_mat_r[i][i] = hi[0]
            pred_mat_i[i][i] = hi[1]

        for i, hx in enumerate(hij):
            pred_mat_r[ij[0][i]][ij[1][i]] = hx[0]
            pred_mat_i[ij[0][i]][ij[1][i]] = hx[1]

        target_mat_r = torch.zeros([len(hii), len(hii)])
        target_mat_i = torch.zeros([len(hii), len(hii)])
        for i, hi in enumerate(inputs.onsite):
            target_mat_r[i][i] = hi[0]
            target_mat_i[i][i] = hi[1]
        for i, hx in enumerate(inputs.hop):
            target_mat_r[ij[0][i]][ij[1][i]] = hx[0]
            target_mat_i[ij[0][i]][ij[1][i]] = hx[1]

        dif_mat_i = target_mat_i - pred_mat_i

        dif_mat_r = target_mat_r - pred_mat_r

        path = f"{exp_name}/rezults"
        plot_matrx(target_mat_r, name=f'/img/{ko}_tar_rmag.png', path=path)

        plot_matrx(pred_mat_r, name=f'/img/{ko}_pred_rmag.png', path=path)

        plot_matrx(dif_mat_r, name=f'/img/{ko}_dif_real.png', path=path)

        plot_matrx(dif_mat_i, name=f'/img/{ko}_dif_imag.png', path=path)
        print("Done")
        print("maxx:",dif_mat_r.max() )
        print("min:", dif_mat_r.min())
        mat = dif_mat_r.detach().numpy()
        with open(f'{path}/txt/{ko}_dif_rea.txt', 'wb') as f:
            for line in mat:
                np.savetxt(f, line, fmt='%.3f')
        mat = target_mat_r.detach().numpy()
        with open(f'{path}/txt/{ko}_target_mat_r.txt', 'wb') as f:
            for line in mat:
                np.savetxt(f, line, fmt='%.3f')
        mat = pred_mat_r.detach().numpy()
        with open(f'{path}/txt/{ko}_pred_mat_r.txt', 'wb') as f:
            for line in mat:
                np.savetxt(f, line, fmt='%.3f')

        if ko == 3:
            break

if __name__ == "__main__":
    main()